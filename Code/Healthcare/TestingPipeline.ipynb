{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5134137",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- extarct from MongoDB\n",
    "- clean and transform \n",
    "- saved LDA model for topic\n",
    "- sentiment analysis (VADER)\n",
    "- ML model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4176e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import models\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ac76de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (120, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initializing the client\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "# Database names containing the posts\n",
    "database_names = [\"healthcare_data_stream\"]\n",
    "\n",
    "# List to store documents\n",
    "all_documents = []\n",
    "\n",
    "for db_name in database_names:\n",
    "    db = client[db_name]\n",
    "    for collection_name in db.list_collection_names():\n",
    "        collection = db[collection_name]\n",
    "        cursor = collection.find({})\n",
    "        for document in cursor:\n",
    "            document[\"subreddit\"] = db_name\n",
    "            all_documents.append({\n",
    "                \"title\": document.get(\"title\"),\n",
    "                \"created_utc\": pd.to_datetime(document.get(\"created_utc\"), unit='s'),\n",
    "                \"selftext\": document.get(\"selftext\")\n",
    "            })\n",
    "\n",
    "# Converting list of dicts into a DataFrame\n",
    "healthcare_df = pd.DataFrame(all_documents)\n",
    "# Shape\n",
    "print(\"Shape of the DataFrame:\", healthcare_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b499fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a8d35c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please, if you are in Cairo, hit me up.</td>\n",
       "      <td>2024-05-14 13:35:59</td>\n",
       "      <td>I don't want to do it alone, so, please, lets ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just takes over me</td>\n",
       "      <td>2024-05-14 13:33:02</td>\n",
       "      <td>It will vary on days like sadness, disappointm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>2024-05-14 13:32:22</td>\n",
       "      <td>\\n3 years of this shit. Even if I recover, I’m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet people</td>\n",
       "      <td>2024-05-14 13:25:12</td>\n",
       "      <td>Hello. Is there abydoby I can speak to? i,'m f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-theanine helped me get out of bed</td>\n",
       "      <td>2024-05-14 13:07:20</td>\n",
       "      <td>So on what I thought was a long shot I bought ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         created_utc  \\\n",
       "0            Please, if you are in Cairo, hit me up. 2024-05-14 13:35:59   \n",
       "1                             It just takes over me  2024-05-14 13:33:02   \n",
       "2  Days like today I wish my chronic illness was ... 2024-05-14 13:32:22   \n",
       "3                                        Meet people 2024-05-14 13:25:12   \n",
       "4                L-theanine helped me get out of bed 2024-05-14 13:07:20   \n",
       "\n",
       "                                            selftext  \n",
       "0  I don't want to do it alone, so, please, lets ...  \n",
       "1  It will vary on days like sadness, disappointm...  \n",
       "2  \\n3 years of this shit. Even if I recover, I’m...  \n",
       "3  Hello. Is there abydoby I can speak to? i,'m f...  \n",
       "4  So on what I thought was a long shot I bought ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthcare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7af79128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "created_utc    0\n",
       "selftext       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nulls\n",
    "healthcare_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9dd14d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthcare_df['text'] = healthcare_df['title'] + ' ' + healthcare_df['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "256e4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# healthcare_df[healthcare_df['text']==\" \"]  # check if there is any empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "52c7b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing and cleaning \n",
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    #Check NaN\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    #Convert lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    #Remove text within brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    #Remove emojis\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    #Remove additional parentheses\n",
    "    text = re.sub(r'\\(+\\)', '', text)\n",
    "    \n",
    "    #Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    #Remove newline characters and extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text.replace('\\n', ' ').strip())\n",
    "    \n",
    "    #Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    #Remove hashtags (words starting with '#')\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    #Remove mentions (words starting with '@')\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20cbad5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sssri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sssri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sssri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "449adf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning \n",
    "healthcare_df['text_cleaned'] = healthcare_df['text'].apply(clean_text)\n",
    "#text pre procesing\n",
    "healthcare_df['text_processed'] = healthcare_df['text_cleaned'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e5ff4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please, if you are in Cairo, hit me up.</td>\n",
       "      <td>2024-05-14 13:35:59</td>\n",
       "      <td>I don't want to do it alone, so, please, lets ...</td>\n",
       "      <td>Please, if you are in Cairo, hit me up. I don'...</td>\n",
       "      <td>please if you are in cairo hit me up i dont wa...</td>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just takes over me</td>\n",
       "      <td>2024-05-14 13:33:02</td>\n",
       "      <td>It will vary on days like sadness, disappointm...</td>\n",
       "      <td>It just takes over me  It will vary on days li...</td>\n",
       "      <td>it just takes over me it will vary on days lik...</td>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>2024-05-14 13:32:22</td>\n",
       "      <td>\\n3 years of this shit. Even if I recover, I’m...</td>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>days like today i wish my chronic illness was ...</td>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet people</td>\n",
       "      <td>2024-05-14 13:25:12</td>\n",
       "      <td>Hello. Is there abydoby I can speak to? i,'m f...</td>\n",
       "      <td>Meet people Hello. Is there abydoby I can spea...</td>\n",
       "      <td>meet people hello is there abydoby i can speak...</td>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-theanine helped me get out of bed</td>\n",
       "      <td>2024-05-14 13:07:20</td>\n",
       "      <td>So on what I thought was a long shot I bought ...</td>\n",
       "      <td>L-theanine helped me get out of bed So on what...</td>\n",
       "      <td>ltheanine helped me get out of bed so on what ...</td>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         created_utc  \\\n",
       "0            Please, if you are in Cairo, hit me up. 2024-05-14 13:35:59   \n",
       "1                             It just takes over me  2024-05-14 13:33:02   \n",
       "2  Days like today I wish my chronic illness was ... 2024-05-14 13:32:22   \n",
       "3                                        Meet people 2024-05-14 13:25:12   \n",
       "4                L-theanine helped me get out of bed 2024-05-14 13:07:20   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  I don't want to do it alone, so, please, lets ...   \n",
       "1  It will vary on days like sadness, disappointm...   \n",
       "2  \\n3 years of this shit. Even if I recover, I’m...   \n",
       "3  Hello. Is there abydoby I can speak to? i,'m f...   \n",
       "4  So on what I thought was a long shot I bought ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Please, if you are in Cairo, hit me up. I don'...   \n",
       "1  It just takes over me  It will vary on days li...   \n",
       "2  Days like today I wish my chronic illness was ...   \n",
       "3  Meet people Hello. Is there abydoby I can spea...   \n",
       "4  L-theanine helped me get out of bed So on what...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  please if you are in cairo hit me up i dont wa...   \n",
       "1  it just takes over me it will vary on days lik...   \n",
       "2  days like today i wish my chronic illness was ...   \n",
       "3  meet people hello is there abydoby i can speak...   \n",
       "4  ltheanine helped me get out of bed so on what ...   \n",
       "\n",
       "                                      text_processed  \n",
       "0  please cairo hit dont want alone please let to...  \n",
       "1  take vary day like sadness disappointment lone...  \n",
       "2  day like today wish chronic illness terminal y...  \n",
       "3  meet people hello abydoby speak im feeling lonely  \n",
       "4  ltheanine helped get bed thought long shot bou...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthcare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19be5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "719a77d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please, if you are in Cairo, hit me up.</td>\n",
       "      <td>2024-05-14 13:35:59</td>\n",
       "      <td>I don't want to do it alone, so, please, lets ...</td>\n",
       "      <td>Please, if you are in Cairo, hit me up. I don'...</td>\n",
       "      <td>please if you are in cairo hit me up i dont wa...</td>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.629661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just takes over me</td>\n",
       "      <td>2024-05-14 13:33:02</td>\n",
       "      <td>It will vary on days like sadness, disappointm...</td>\n",
       "      <td>It just takes over me  It will vary on days li...</td>\n",
       "      <td>it just takes over me it will vary on days lik...</td>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.649418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>2024-05-14 13:32:22</td>\n",
       "      <td>\\n3 years of this shit. Even if I recover, I’m...</td>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>days like today i wish my chronic illness was ...</td>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.664479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet people</td>\n",
       "      <td>2024-05-14 13:25:12</td>\n",
       "      <td>Hello. Is there abydoby I can speak to? i,'m f...</td>\n",
       "      <td>Meet people Hello. Is there abydoby I can spea...</td>\n",
       "      <td>meet people hello is there abydoby i can speak...</td>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.739658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-theanine helped me get out of bed</td>\n",
       "      <td>2024-05-14 13:07:20</td>\n",
       "      <td>So on what I thought was a long shot I bought ...</td>\n",
       "      <td>L-theanine helped me get out of bed So on what...</td>\n",
       "      <td>ltheanine helped me get out of bed so on what ...</td>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         created_utc  \\\n",
       "0            Please, if you are in Cairo, hit me up. 2024-05-14 13:35:59   \n",
       "1                             It just takes over me  2024-05-14 13:33:02   \n",
       "2  Days like today I wish my chronic illness was ... 2024-05-14 13:32:22   \n",
       "3                                        Meet people 2024-05-14 13:25:12   \n",
       "4                L-theanine helped me get out of bed 2024-05-14 13:07:20   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  I don't want to do it alone, so, please, lets ...   \n",
       "1  It will vary on days like sadness, disappointm...   \n",
       "2  \\n3 years of this shit. Even if I recover, I’m...   \n",
       "3  Hello. Is there abydoby I can speak to? i,'m f...   \n",
       "4  So on what I thought was a long shot I bought ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Please, if you are in Cairo, hit me up. I don'...   \n",
       "1  It just takes over me  It will vary on days li...   \n",
       "2  Days like today I wish my chronic illness was ...   \n",
       "3  Meet people Hello. Is there abydoby I can spea...   \n",
       "4  L-theanine helped me get out of bed So on what...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  please if you are in cairo hit me up i dont wa...   \n",
       "1  it just takes over me it will vary on days lik...   \n",
       "2  days like today i wish my chronic illness was ...   \n",
       "3  meet people hello is there abydoby i can speak...   \n",
       "4  ltheanine helped me get out of bed so on what ...   \n",
       "\n",
       "                                      text_processed  topic  topic_probability  \n",
       "0  please cairo hit dont want alone please let to...    3.0           0.629661  \n",
       "1  take vary day like sadness disappointment lone...    3.0           0.649418  \n",
       "2  day like today wish chronic illness terminal y...    3.0           0.664479  \n",
       "3  meet people hello abydoby speak im feeling lonely    3.0           0.739658  \n",
       "4  ltheanine helped get bed thought long shot bou...    0.0           0.774321  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the dictionary and LDA model\n",
    "dictionary = corpora.Dictionary.load(\"dictionary.gensim\")\n",
    "lda_model = models.LdaModel.load(\"lda_model.gensim\")\n",
    "\n",
    "# Function to preprocess a single post\n",
    "def preprocess_post(post):\n",
    "    tokenized_post = word_tokenize(post.lower())\n",
    "    tokenized_post = [word for word in tokenized_post if word not in stopwords.words('english')]\n",
    "    return tokenized_post\n",
    "\n",
    "# Apply LDA model to each post using apply function\n",
    "def infer_topic(post):\n",
    "    tokenized_post = preprocess_post(post)\n",
    "    bow_post = dictionary.doc2bow(tokenized_post)\n",
    "    topic_distribution = lda_model.get_document_topics(bow_post)\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])\n",
    "    return dominant_topic[0], dominant_topic[1]\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "healthcare_df[['topic', 'topic_probability']] = healthcare_df['text_processed'].apply(infer_topic).apply(pd.Series)\n",
    "\n",
    "healthcare_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b230ff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "3.0    52\n",
       "0.0    35\n",
       "1.0    23\n",
       "2.0    10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthcare_df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b247f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\sssri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# apply sentiment analysis using VADER\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download the VADER lexicon if not already downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# Function to classify sentiment as positive, negative, or neutral\n",
    "def get_sentiment_label(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)['compound']\n",
    "    if sentiment_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35e0c783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_probability</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please, if you are in Cairo, hit me up.</td>\n",
       "      <td>2024-05-14 13:35:59</td>\n",
       "      <td>I don't want to do it alone, so, please, lets ...</td>\n",
       "      <td>Please, if you are in Cairo, hit me up. I don'...</td>\n",
       "      <td>please if you are in cairo hit me up i dont wa...</td>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.629661</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just takes over me</td>\n",
       "      <td>2024-05-14 13:33:02</td>\n",
       "      <td>It will vary on days like sadness, disappointm...</td>\n",
       "      <td>It just takes over me  It will vary on days li...</td>\n",
       "      <td>it just takes over me it will vary on days lik...</td>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.649418</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>2024-05-14 13:32:22</td>\n",
       "      <td>\\n3 years of this shit. Even if I recover, I’m...</td>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>days like today i wish my chronic illness was ...</td>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.664479</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet people</td>\n",
       "      <td>2024-05-14 13:25:12</td>\n",
       "      <td>Hello. Is there abydoby I can speak to? i,'m f...</td>\n",
       "      <td>Meet people Hello. Is there abydoby I can spea...</td>\n",
       "      <td>meet people hello is there abydoby i can speak...</td>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.739658</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-theanine helped me get out of bed</td>\n",
       "      <td>2024-05-14 13:07:20</td>\n",
       "      <td>So on what I thought was a long shot I bought ...</td>\n",
       "      <td>L-theanine helped me get out of bed So on what...</td>\n",
       "      <td>ltheanine helped me get out of bed so on what ...</td>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         created_utc  \\\n",
       "0            Please, if you are in Cairo, hit me up. 2024-05-14 13:35:59   \n",
       "1                             It just takes over me  2024-05-14 13:33:02   \n",
       "2  Days like today I wish my chronic illness was ... 2024-05-14 13:32:22   \n",
       "3                                        Meet people 2024-05-14 13:25:12   \n",
       "4                L-theanine helped me get out of bed 2024-05-14 13:07:20   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  I don't want to do it alone, so, please, lets ...   \n",
       "1  It will vary on days like sadness, disappointm...   \n",
       "2  \\n3 years of this shit. Even if I recover, I’m...   \n",
       "3  Hello. Is there abydoby I can speak to? i,'m f...   \n",
       "4  So on what I thought was a long shot I bought ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Please, if you are in Cairo, hit me up. I don'...   \n",
       "1  It just takes over me  It will vary on days li...   \n",
       "2  Days like today I wish my chronic illness was ...   \n",
       "3  Meet people Hello. Is there abydoby I can spea...   \n",
       "4  L-theanine helped me get out of bed So on what...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  please if you are in cairo hit me up i dont wa...   \n",
       "1  it just takes over me it will vary on days lik...   \n",
       "2  days like today i wish my chronic illness was ...   \n",
       "3  meet people hello is there abydoby i can speak...   \n",
       "4  ltheanine helped me get out of bed so on what ...   \n",
       "\n",
       "                                      text_processed  topic  \\\n",
       "0  please cairo hit dont want alone please let to...    3.0   \n",
       "1  take vary day like sadness disappointment lone...    3.0   \n",
       "2  day like today wish chronic illness terminal y...    3.0   \n",
       "3  meet people hello abydoby speak im feeling lonely    3.0   \n",
       "4  ltheanine helped get bed thought long shot bou...    0.0   \n",
       "\n",
       "   topic_probability sentiment  \n",
       "0           0.629661  Positive  \n",
       "1           0.649418  Negative  \n",
       "2           0.664479  Negative  \n",
       "3           0.739658  Negative  \n",
       "4           0.774321  Positive  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply sentiment analysis to each row of 'selftext_cleaned' and 'title_cleaned' columns\n",
    "healthcare_df['sentiment'] = healthcare_df['text_cleaned'].apply(get_sentiment_label)\n",
    "healthcare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cc1dfcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    79\n",
       "Positive    35\n",
       "Neutral      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthcare_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f66ef893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_probability</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please, if you are in Cairo, hit me up.</td>\n",
       "      <td>2024-05-14 13:35:59</td>\n",
       "      <td>I don't want to do it alone, so, please, lets ...</td>\n",
       "      <td>Please, if you are in Cairo, hit me up. I don'...</td>\n",
       "      <td>please if you are in cairo hit me up i dont wa...</td>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.629661</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It just takes over me</td>\n",
       "      <td>2024-05-14 13:33:02</td>\n",
       "      <td>It will vary on days like sadness, disappointm...</td>\n",
       "      <td>It just takes over me  It will vary on days li...</td>\n",
       "      <td>it just takes over me it will vary on days lik...</td>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.649418</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>2024-05-14 13:32:22</td>\n",
       "      <td>\\n3 years of this shit. Even if I recover, I’m...</td>\n",
       "      <td>Days like today I wish my chronic illness was ...</td>\n",
       "      <td>days like today i wish my chronic illness was ...</td>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.664479</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meet people</td>\n",
       "      <td>2024-05-14 13:25:12</td>\n",
       "      <td>Hello. Is there abydoby I can speak to? i,'m f...</td>\n",
       "      <td>Meet people Hello. Is there abydoby I can spea...</td>\n",
       "      <td>meet people hello is there abydoby i can speak...</td>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.739658</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L-theanine helped me get out of bed</td>\n",
       "      <td>2024-05-14 13:07:20</td>\n",
       "      <td>So on what I thought was a long shot I bought ...</td>\n",
       "      <td>L-theanine helped me get out of bed So on what...</td>\n",
       "      <td>ltheanine helped me get out of bed so on what ...</td>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.774321</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         created_utc  \\\n",
       "0            Please, if you are in Cairo, hit me up. 2024-05-14 13:35:59   \n",
       "1                             It just takes over me  2024-05-14 13:33:02   \n",
       "2  Days like today I wish my chronic illness was ... 2024-05-14 13:32:22   \n",
       "3                                        Meet people 2024-05-14 13:25:12   \n",
       "4                L-theanine helped me get out of bed 2024-05-14 13:07:20   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  I don't want to do it alone, so, please, lets ...   \n",
       "1  It will vary on days like sadness, disappointm...   \n",
       "2  \\n3 years of this shit. Even if I recover, I’m...   \n",
       "3  Hello. Is there abydoby I can speak to? i,'m f...   \n",
       "4  So on what I thought was a long shot I bought ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Please, if you are in Cairo, hit me up. I don'...   \n",
       "1  It just takes over me  It will vary on days li...   \n",
       "2  Days like today I wish my chronic illness was ...   \n",
       "3  Meet people Hello. Is there abydoby I can spea...   \n",
       "4  L-theanine helped me get out of bed So on what...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  please if you are in cairo hit me up i dont wa...   \n",
       "1  it just takes over me it will vary on days lik...   \n",
       "2  days like today i wish my chronic illness was ...   \n",
       "3  meet people hello is there abydoby i can speak...   \n",
       "4  ltheanine helped me get out of bed so on what ...   \n",
       "\n",
       "                                      text_processed  topic  \\\n",
       "0  please cairo hit dont want alone please let to...    3.0   \n",
       "1  take vary day like sadness disappointment lone...    3.0   \n",
       "2  day like today wish chronic illness terminal y...    3.0   \n",
       "3  meet people hello abydoby speak im feeling lonely    3.0   \n",
       "4  ltheanine helped get bed thought long shot bou...    0.0   \n",
       "\n",
       "   topic_probability sentiment  \n",
       "0           0.629661  Positive  \n",
       "1           0.649418  Negative  \n",
       "2           0.664479  Negative  \n",
       "3           0.739658  Negative  \n",
       "4           0.774321  Positive  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthcare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6423018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  topic sentiment\n",
       "0  please cairo hit dont want alone please let to...    3.0  Positive\n",
       "1  take vary day like sadness disappointment lone...    3.0  Negative\n",
       "2  day like today wish chronic illness terminal y...    3.0  Negative\n",
       "3  meet people hello abydoby speak im feeling lonely    3.0  Negative\n",
       "4  ltheanine helped get bed thought long shot bou...    0.0  Positive"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf=healthcare_df[['text_processed','topic','sentiment']]\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "871248a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('best_model_split_0.8.pkl', 'rb') as f:\n",
    "#     model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd4171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6154d510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "070ea5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finaldf.rename(columns={'sentiment':'sentiment_1'},inplace=True)\n",
    "# finaldf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "404743ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  topic sentiment\n",
       "0  please cairo hit dont want alone please let to...    3.0  Positive\n",
       "1  take vary day like sadness disappointment lone...    3.0  Negative\n",
       "2  day like today wish chronic illness terminal y...    3.0  Negative\n",
       "3  meet people hello abydoby speak im feeling lonely    3.0  Negative\n",
       "4  ltheanine helped get bed thought long shot bou...    0.0  Positive"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3be73477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  topic  sentiment\n",
       "0  please cairo hit dont want alone please let to...    3.0          2\n",
       "1  take vary day like sadness disappointment lone...    3.0          0\n",
       "2  day like today wish chronic illness terminal y...    3.0          0\n",
       "3  meet people hello abydoby speak im feeling lonely    3.0          0\n",
       "4  ltheanine helped get bed thought long shot bou...    0.0          2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# # encoding the cat to num \n",
    "# # neg- 0 , pos- 2, neutral-1\n",
    "encoder = LabelEncoder()\n",
    "finaldf['sentiment'] = encoder.fit_transform(finaldf['sentiment'])\n",
    "finaldf.head()\n",
    "\n",
    "\n",
    "\n",
    "# # use the sentiment_encoder saved model\n",
    "# # Load the model\n",
    "# with open('sentiment_encoder_final.pkl', 'rb') as f:\n",
    "#     sentiment_encoder_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21ed7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f6a0156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# vectorizer\n",
    "vectorizer = joblib.load('vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b7185ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = vectorizer.transform(finaldf['text_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7533f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the types to str\n",
    "finaldf['topic']=finaldf['topic'].astype(str)\n",
    "finaldf['sentiment']=finaldf['sentiment'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3c408f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_processed    object\n",
       "topic             object\n",
       "sentiment         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "36130ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical = pd.concat([pd.DataFrame(X_text.toarray()), pd.DataFrame(finaldf, columns=['sentiment','topic'])],\n",
    "                        axis=1)\n",
    "\n",
    "# X_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5f77a96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical.columns = X_numerical.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9958b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = joblib.load('final_model_split_0.8.pkl')  # load the model\n",
    "\n",
    "predictions = best_model.predict(X_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a56f8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add predictions to the dataframe\n",
    "finaldf['prediction'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "56b044fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>really last word first time second time realized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>actually brushed teeth today actually brushed ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>relationship withdrawal weight alive feel much...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>soon get close someone trauma dump share title...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>useless nothing im biggest waste space ever im...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_processed topic sentiment  \\\n",
       "0    please cairo hit dont want alone please let to...   3.0         2   \n",
       "1    take vary day like sadness disappointment lone...   3.0         0   \n",
       "2    day like today wish chronic illness terminal y...   3.0         0   \n",
       "3    meet people hello abydoby speak im feeling lonely   3.0         0   \n",
       "4    ltheanine helped get bed thought long shot bou...   0.0         2   \n",
       "..                                                 ...   ...       ...   \n",
       "115   really last word first time second time realized   1.0         1   \n",
       "116  actually brushed teeth today actually brushed ...   1.0         0   \n",
       "117  relationship withdrawal weight alive feel much...   3.0         0   \n",
       "118  soon get close someone trauma dump share title...   3.0         0   \n",
       "119  useless nothing im biggest waste space ever im...   3.0         0   \n",
       "\n",
       "     prediction  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "..          ...  \n",
       "115           1  \n",
       "116           1  \n",
       "117           1  \n",
       "118           1  \n",
       "119           1  \n",
       "\n",
       "[120 rows x 4 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856032da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg- 0 , pos- 2, neutral-1\n",
    "# Label 0: anxiety\n",
    "# Label 1: depression\n",
    "# Topic 0 : Seeking Support\n",
    "# Topic 1 : Life Events and Relationships\n",
    "# Topic 2 : Social Anxiety and Work Challenges\n",
    "# Topic 3 : Difficulty with Relationships and Life in General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a9c2aa89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.topic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ab3bf9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "anxiety       62\n",
       "depression    58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "83578e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mappings\n",
    "label_mapping = {0: \"anxiety\", 1: \"depression\"}\n",
    "topic_mapping = {'0.0': \"Seeking Support\", '1.0': \"Life Events and Relationships\", '2.0': \"Social Anxiety and Work Challenges\", '3.0': \"Difficulty with Relationships and Life in General\"}\n",
    "sentiment_mapping = {'0': \"Negative\", '1': \"Neutral\", '2': \"Positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8b083b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Positive</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>Seeking Support</td>\n",
       "      <td>Positive</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  \\\n",
       "0  please cairo hit dont want alone please let to...   \n",
       "1  take vary day like sadness disappointment lone...   \n",
       "2  day like today wish chronic illness terminal y...   \n",
       "3  meet people hello abydoby speak im feeling lonely   \n",
       "4  ltheanine helped get bed thought long shot bou...   \n",
       "\n",
       "                                               topic sentiment  prediction  \n",
       "0  Difficulty with Relationships and Life in General  Positive  depression  \n",
       "1  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "2  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "3  Difficulty with Relationships and Life in General  Negative     anxiety  \n",
       "4                                    Seeking Support  Positive  depression  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map labels, topics, and sentiments to their corresponding names\n",
    "finaldf[\"prediction\"] = finaldf[\"prediction\"].map(label_mapping)\n",
    "finaldf[\"topic\"] = finaldf[\"topic\"].map(topic_mapping)\n",
    "finaldf[\"sentiment\"] = finaldf[\"sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e6ef4afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Difficulty with Relationships and Life in General    52\n",
       "Seeking Support                                      35\n",
       "Life Events and Relationships                        23\n",
       "Social Anxiety and Work Challenges                   10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f7daa55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negative    79\n",
       "Positive    35\n",
       "Neutral      6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d0ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f7e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7f0b3652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Positive</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>Seeking Support</td>\n",
       "      <td>Positive</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  \\\n",
       "0  please cairo hit dont want alone please let to...   \n",
       "1  take vary day like sadness disappointment lone...   \n",
       "2  day like today wish chronic illness terminal y...   \n",
       "3  meet people hello abydoby speak im feeling lonely   \n",
       "4  ltheanine helped get bed thought long shot bou...   \n",
       "\n",
       "                                               topic sentiment  prediction  \n",
       "0  Difficulty with Relationships and Life in General  Positive  depression  \n",
       "1  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "2  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "3  Difficulty with Relationships and Life in General  Negative     anxiety  \n",
       "4                                    Seeking Support  Positive  depression  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bdfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539aad0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94893e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e702cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a55309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c455a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a61713c",
   "metadata": {},
   "source": [
    "#### single input string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4a57504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Result:\n",
      "Emotional State: depression\n",
      "Sentiment: Negative\n",
      "Topic: Difficulty with Relationships and Life in General (Probability: 0.81)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from gensim import corpora, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    # Check for NaN\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove text within brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Remove additional parentheses\n",
    "    text = re.sub(r'\\(+\\)', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove newline characters and extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text.replace('\\n', ' ').strip())\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "    # Remove hashtags (words starting with '#')\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    \n",
    "    # Remove mentions (words starting with '@')\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Load the pre-trained model and vectorizer\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "best_model = joblib.load('final_model_split_0.8.pkl')\n",
    "lda_model = models.LdaModel.load(\"lda_model.gensim\")\n",
    "dictionary = corpora.Dictionary.load(\"dictionary.gensim\")\n",
    "# Load sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define mappings\n",
    "label_mapping = {0: \"anxiety\", 1: \"depression\"}\n",
    "topic_mapping = {'0': \"Seeking Support\", '1': \"Life Events and Relationships\", '2': \"Social Anxiety and Work Challenges\", '3': \"Difficulty with Relationships and Life in General\"}\n",
    "sentiment_mapping = {'0': \"Negative\", '1': \"Neutral\", '2': \"Positive\"}\n",
    "\n",
    "# Function to classify sentiment as positive, negative, or neutral\n",
    "def get_sentiment_label(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)['compound']\n",
    "    if sentiment_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# User text\n",
    "user_text = \"i wanna die\"\n",
    "\n",
    "# Data preprocessing\n",
    "cleaned_text = clean_text(user_text)\n",
    "preprocessed_text = preprocess_text(cleaned_text)\n",
    "\n",
    "# Sentiment analysis\n",
    "sentiment = get_sentiment_label(preprocessed_text)\n",
    "encoder = LabelEncoder()\n",
    "sentiment = encoder.fit_transform([sentiment])[0]\n",
    "\n",
    "# Apply LDA model to each post using apply function\n",
    "def infer_topic(post):\n",
    "    tokenized_post = preprocess_text(post)\n",
    "    bow_post = dictionary.doc2bow(tokenized_post.split())\n",
    "    topic_distribution = lda_model.get_document_topics(bow_post)\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])\n",
    "    return dominant_topic[0], dominant_topic[1]\n",
    "\n",
    "# Apply the function to the user text\n",
    "topic, topic_probability = infer_topic(preprocessed_text)\n",
    "\n",
    "# Prediction using pre-trained model\n",
    "X_text = vectorizer.transform([preprocessed_text])\n",
    "X_text_df = pd.DataFrame(X_text.toarray())\n",
    "X_numerical = pd.concat([X_text_df, pd.DataFrame({'sentiment': sentiment, 'topic': str(topic)}, index=[0])], axis=1)\n",
    "X_numerical.columns = X_numerical.columns.astype(str)\n",
    "\n",
    "# Predict label\n",
    "prediction = best_model.predict(X_numerical)\n",
    "label = label_mapping[prediction[0]]\n",
    "\n",
    "# Display result\n",
    "print(\"Analysis Result:\")\n",
    "print(f\"Emotional State: {label}\")\n",
    "print(f\"Sentiment: {sentiment_mapping[str(sentiment)]}\")\n",
    "print(f\"Topic: {topic_mapping[str(topic)]} (Probability: {topic_probability:.2f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c1f6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d7ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d22f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Result:\n",
      "Emotional State: Not Depression/Not Anxiety\n",
      "Analysis Result:\n",
      "Emotional State: depression\n",
      "Sentiment: Negative\n",
      "Topic: Social Anxiety and Work Challenges (Probability: 0.51)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from gensim import corpora, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Function to clean text data\n",
    "def clean_text(text):\n",
    "    # Check for NaN\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove text within brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # Remove emojis\n",
    "    text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Remove additional parentheses\n",
    "    text = re.sub(r'\\(+\\)', '', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove newline characters and extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text.replace('\\n', ' ').strip())\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Remove hashtags (words starting with '#')\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "\n",
    "    # Remove mentions (words starting with '@')\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "# Load the pre-trained model and vectorizer\n",
    "vectorizer = joblib.load('vectorizer.pkl')\n",
    "best_model = joblib.load('final_model_split_0.8.pkl')\n",
    "lda_model = models.LdaModel.load(\"lda_model.gensim\")\n",
    "dictionary = corpora.Dictionary.load(\"dictionary.gensim\")\n",
    "# Load sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define mappings\n",
    "label_mapping = {0: \"anxiety\", 1: \"depression\"}\n",
    "topic_mapping = {'0': \"Seeking Support\", '1': \"Life Events and Relationships\", '2': \"Social Anxiety and Work Challenges\", '3': \"Difficulty with Relationships and Life in General\"}\n",
    "sentiment_mapping = {'0': \"Negative\", '1': \"Neutral\", '2': \"Positive\"}\n",
    "\n",
    "# Function to classify sentiment as positive, negative, or neutral\n",
    "def get_sentiment_label(text):\n",
    "    sentiment_score = analyzer.polarity_scores(text)['compound']\n",
    "    if sentiment_score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# User text\n",
    "user_text = \"i am happy to be here to share my experience realted to my past depressin \"\n",
    "\n",
    "# Data preprocessing\n",
    "cleaned_text = clean_text(user_text)\n",
    "preprocessed_text = preprocess_text(cleaned_text)\n",
    "\n",
    "# Define words not related to depression/anxiety (adjust this list)\n",
    "irrelevant_words = [\"happy\", \"joyful\", \"excited\", \"good\", \"great\", \"celebrating\", \"achievement\"]\n",
    "\n",
    "# Check for irrelevant words (early exit if present)\n",
    "if any(word in preprocessed_text.split() for word in irrelevant_words):\n",
    "    print(\"Analysis Result:\")\n",
    "    print(f\"Emotional State: Not Depression/Not Anxiety\")\n",
    "    exit()  \n",
    "\n",
    "# Sentiment analysis\n",
    "sentiment = get_sentiment_label(preprocessed_text)\n",
    "encoder = LabelEncoder()\n",
    "sentiment = encoder.fit_transform([sentiment])[0]\n",
    "# Apply LDA model to each post using apply function\n",
    "def infer_topic(post):\n",
    "    tokenized_post = preprocess_text(post)\n",
    "    bow_post = dictionary.doc2bow(tokenized_post.split())\n",
    "    topic_distribution = lda_model.get_document_topics(bow_post)\n",
    "    dominant_topic = max(topic_distribution, key=lambda x: x[1])\n",
    "    return dominant_topic[0], dominant_topic[1]\n",
    "\n",
    "# Apply the function to the user text\n",
    "topic, topic_probability = infer_topic(preprocessed_text)\n",
    "\n",
    "# Prediction using pre-trained model\n",
    "X_text = vectorizer.transform([preprocessed_text])\n",
    "X_text_df = pd.DataFrame(X_text.toarray())\n",
    "X_numerical = pd.concat([X_text_df, pd.DataFrame({'sentiment': sentiment, 'topic': str(topic)}, index=[0])], axis=1)\n",
    "X_numerical.columns = X_numerical.columns.astype(str)\n",
    "\n",
    "# Predict label\n",
    "prediction = best_model.predict(X_numerical)\n",
    "label = label_mapping[prediction[0]]\n",
    "\n",
    "# Display result\n",
    "print(\"Analysis Result:\")\n",
    "print(f\"Emotional State: {label}\")\n",
    "print(f\"Sentiment: {sentiment_mapping[str(sentiment)]}\")\n",
    "print(f\"Topic: {topic_mapping[str(topic)]} (Probability: {topic_probability:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5aa38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f51e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f9583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd405d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af45c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1126fe0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ffdbc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1691f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310a1ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336606a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb68be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef6456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e749a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f60d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e408b17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12                                     could reason girl\n",
       "17     taking total xanax everyday much take morning ...\n",
       "37      really last word first time second time realized\n",
       "55                                     could reason girl\n",
       "94     taking total xanax everyday much take morning ...\n",
       "115     really last word first time second time realized\n",
       "Name: text_processed, dtype: object"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=finaldf[finaldf['sentiment']==\"Neutral\"][['prediction','text_processed']]\n",
    "a.text_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1c5bcb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'taking total xanax everyday much take morning night much'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.text_processed[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fef9e2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "63e9d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>please cairo hit dont want alone please let to...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Positive</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take vary day like sadness disappointment lone...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day like today wish chronic illness terminal y...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet people hello abydoby speak im feeling lonely</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ltheanine helped get bed thought long shot bou...</td>\n",
       "      <td>Seeking Support</td>\n",
       "      <td>Positive</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>relationship im year old adult nil experience ...</td>\n",
       "      <td>Social Anxiety and Work Challenges</td>\n",
       "      <td>Positive</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>feeling threatened trauma response replay flip...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Positive</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>anyone sh option normally used cut got boring ...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>soon get close someone trauma dump share title...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>useless nothing im biggest waste space ever im...</td>\n",
       "      <td>Difficulty with Relationships and Life in General</td>\n",
       "      <td>Negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_processed  \\\n",
       "0    please cairo hit dont want alone please let to...   \n",
       "1    take vary day like sadness disappointment lone...   \n",
       "2    day like today wish chronic illness terminal y...   \n",
       "3    meet people hello abydoby speak im feeling lonely   \n",
       "4    ltheanine helped get bed thought long shot bou...   \n",
       "..                                                 ...   \n",
       "108  relationship im year old adult nil experience ...   \n",
       "109  feeling threatened trauma response replay flip...   \n",
       "112  anyone sh option normally used cut got boring ...   \n",
       "118  soon get close someone trauma dump share title...   \n",
       "119  useless nothing im biggest waste space ever im...   \n",
       "\n",
       "                                                 topic sentiment  prediction  \n",
       "0    Difficulty with Relationships and Life in General  Positive  depression  \n",
       "1    Difficulty with Relationships and Life in General  Negative  depression  \n",
       "2    Difficulty with Relationships and Life in General  Negative  depression  \n",
       "3    Difficulty with Relationships and Life in General  Negative     anxiety  \n",
       "4                                      Seeking Support  Positive  depression  \n",
       "..                                                 ...       ...         ...  \n",
       "108                 Social Anxiety and Work Challenges  Positive     anxiety  \n",
       "109  Difficulty with Relationships and Life in General  Positive     anxiety  \n",
       "112  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "118  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "119  Difficulty with Relationships and Life in General  Negative  depression  \n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19a9d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
