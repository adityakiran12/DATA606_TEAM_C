{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d59558a",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2346bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2775bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('trail_healthcare.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f61bbc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishing didnt life anymore looking fellow depr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy hate live live busiest street town full ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed boyfriend want leave mum died hi ive...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said something embarrassing panic attack texti...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone please reassure im overly thinking anx...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  topic sentiment_1  \\\n",
       "0  wishing didnt life anymore looking fellow depr...    0.0    negative   \n",
       "1  happy hate live live busiest street town full ...    2.0    negative   \n",
       "2  depressed boyfriend want leave mum died hi ive...    2.0    negative   \n",
       "3  said something embarrassing panic attack texti...    2.0    negative   \n",
       "4  someone please reassure im overly thinking anx...    1.0    negative   \n",
       "\n",
       "          tag  \n",
       "0  depression  \n",
       "1  depression  \n",
       "2  depression  \n",
       "3     anxiety  \n",
       "4     anxiety  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data['tag'] = data['tag'].apply(lambda x: x.lower())\n",
    "\n",
    "data['sentiment_1'] = data['sentiment_1'].apply(lambda x: x.lower())\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85c56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8c51f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test-Validation Split: 0.75\n",
      "Training and evaluating Random Forest model...\n",
      "\n",
      "\n",
      "Training and evaluating Decision Tree model...\n",
      "\n",
      "\n",
      "Training and evaluating SVM model...\n",
      "\n",
      "\n",
      "Train-Test-Validation Split: 0.8\n",
      "Training and evaluating Random Forest model...\n",
      "\n",
      "\n",
      "Training and evaluating Decision Tree model...\n",
      "\n",
      "\n",
      "Training and evaluating SVM model...\n",
      "\n",
      "\n",
      "Train-Test-Validation Split: 0.85\n",
      "Training and evaluating Random Forest model...\n",
      "\n",
      "\n",
      "Training and evaluating Decision Tree model...\n",
      "\n",
      "\n",
      "Training and evaluating SVM model...\n",
      "\n",
      "\n",
      "Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Report</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.75</th>\n",
       "      <td>0.876</td>\n",
       "      <td>{'0': {'precision': 0.9118303571428571, 'recal...</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>{'0': {'precision': 0.911839863713799, 'recall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.75</th>\n",
       "      <td>0.8096</td>\n",
       "      <td>{'0': {'precision': 0.854419410745234, 'recall...</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>{'0': {'precision': 0.847465034965035, 'recall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.75</th>\n",
       "      <td>0.888533</td>\n",
       "      <td>{'0': {'precision': 0.9105121293800539, 'recal...</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>{'0': {'precision': 0.9038382170862567, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.8</th>\n",
       "      <td>0.8965</td>\n",
       "      <td>{'0': {'precision': 0.9170603674540683, 'recal...</td>\n",
       "      <td>0.88425</td>\n",
       "      <td>{'0': {'precision': 0.9094804499196572, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.8</th>\n",
       "      <td>0.82275</td>\n",
       "      <td>{'0': {'precision': 0.8523965141612201, 'recal...</td>\n",
       "      <td>0.81175</td>\n",
       "      <td>{'0': {'precision': 0.8478382930937676, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.8</th>\n",
       "      <td>0.906</td>\n",
       "      <td>{'0': {'precision': 0.9169656586365966, 'recal...</td>\n",
       "      <td>0.88975</td>\n",
       "      <td>{'0': {'precision': 0.9020217729393468, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.85</th>\n",
       "      <td>0.886588</td>\n",
       "      <td>{'0': {'precision': 0.905337361530715, 'recall...</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>{'0': {'precision': 0.9086402266288952, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.85</th>\n",
       "      <td>0.823294</td>\n",
       "      <td>{'0': {'precision': 0.8665937670858392, 'recal...</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>{'0': {'precision': 0.8710443037974683, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.85</th>\n",
       "      <td>0.897647</td>\n",
       "      <td>{'0': {'precision': 0.9075258239055582, 'recal...</td>\n",
       "      <td>0.889667</td>\n",
       "      <td>{'0': {'precision': 0.9013112491373361, 'recal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Validation Accuracy  \\\n",
       "Random Forest_0.75               0.876   \n",
       "Decision Tree_0.75              0.8096   \n",
       "SVM_0.75                      0.888533   \n",
       "Random Forest_0.8               0.8965   \n",
       "Decision Tree_0.8              0.82275   \n",
       "SVM_0.8                          0.906   \n",
       "Random Forest_0.85            0.886588   \n",
       "Decision Tree_0.85            0.823294   \n",
       "SVM_0.85                      0.897647   \n",
       "\n",
       "                                                    Validation Report  \\\n",
       "Random Forest_0.75  {'0': {'precision': 0.9118303571428571, 'recal...   \n",
       "Decision Tree_0.75  {'0': {'precision': 0.854419410745234, 'recall...   \n",
       "SVM_0.75            {'0': {'precision': 0.9105121293800539, 'recal...   \n",
       "Random Forest_0.8   {'0': {'precision': 0.9170603674540683, 'recal...   \n",
       "Decision Tree_0.8   {'0': {'precision': 0.8523965141612201, 'recal...   \n",
       "SVM_0.8             {'0': {'precision': 0.9169656586365966, 'recal...   \n",
       "Random Forest_0.85  {'0': {'precision': 0.905337361530715, 'recall...   \n",
       "Decision Tree_0.85  {'0': {'precision': 0.8665937670858392, 'recal...   \n",
       "SVM_0.85            {'0': {'precision': 0.9075258239055582, 'recal...   \n",
       "\n",
       "                   Test Accuracy  \\\n",
       "Random Forest_0.75        0.8886   \n",
       "Decision Tree_0.75        0.8198   \n",
       "SVM_0.75                  0.8932   \n",
       "Random Forest_0.8        0.88425   \n",
       "Decision Tree_0.8        0.81175   \n",
       "SVM_0.8                  0.88975   \n",
       "Random Forest_0.85      0.886667   \n",
       "Decision Tree_0.85      0.814667   \n",
       "SVM_0.85                0.889667   \n",
       "\n",
       "                                                          Test Report  \n",
       "Random Forest_0.75  {'0': {'precision': 0.911839863713799, 'recall...  \n",
       "Decision Tree_0.75  {'0': {'precision': 0.847465034965035, 'recall...  \n",
       "SVM_0.75            {'0': {'precision': 0.9038382170862567, 'recal...  \n",
       "Random Forest_0.8   {'0': {'precision': 0.9094804499196572, 'recal...  \n",
       "Decision Tree_0.8   {'0': {'precision': 0.8478382930937676, 'recal...  \n",
       "SVM_0.8             {'0': {'precision': 0.9020217729393468, 'recal...  \n",
       "Random Forest_0.85  {'0': {'precision': 0.9086402266288952, 'recal...  \n",
       "Decision Tree_0.85  {'0': {'precision': 0.8710443037974683, 'recal...  \n",
       "SVM_0.85            {'0': {'precision': 0.9013112491373361, 'recal...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, param_grid, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # Perform GridSearchCV to find the best hyperparameters\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_accuracy = accuracy_score(y_val, y_pred_val)\n",
    "    val_report = classification_report(y_val, y_pred_val, output_dict=True)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    test_report = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "\n",
    "    return {\n",
    "        \"Validation Accuracy\": val_accuracy,\n",
    "        \"Validation Report\": val_report,\n",
    "        \"Test Accuracy\": test_accuracy,\n",
    "        \"Test Report\": test_report\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data[['text_processed', 'sentiment_1', 'topic']]  # Features: text and sentiment\n",
    "y = data['tag']  # Target variable: tag\n",
    "\n",
    "# Convert text data to numerical using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  \n",
    "X_text = vectorizer.fit_transform(X['text_processed'])\n",
    "\n",
    "# Convert sentiment to numerical using LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "X_sentiment = encoder.fit_transform(X['sentiment_1'])\n",
    "\n",
    "# Combine numerical features (excluding original text)\n",
    "X_numerical = pd.concat([pd.DataFrame(X_text.toarray()), pd.DataFrame(X_sentiment, columns=['sentiment_1'])],\n",
    "                        axis=1)\n",
    "\n",
    "# Convert categorical target variable to numerical using LabelEncoder\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Hyperparameters to search over for each model\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "}\n",
    "\n",
    "# List of models with corresponding parameter grids\n",
    "models = [(\"Random Forest\", RandomForestClassifier(class_weight=\"balanced\"), rf_param_grid),\n",
    "          (\"Decision Tree\", DecisionTreeClassifier(class_weight=\"balanced\"), dt_param_grid),\n",
    "          (\"SVM\", SVC(class_weight=\"balanced\"), svm_param_grid)]\n",
    "\n",
    "# Different train-test-validation splits\n",
    "splits = [0.75, 0.8, 0.85]\n",
    "\n",
    "# Train and evaluate each model for each split\n",
    "results = {}\n",
    "for split in splits:\n",
    "    print(f\"Train-Test-Validation Split: {split}\")\n",
    "    # Stratified Split for data splitting (maintains class distribution)\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=(1 - split), random_state=42)\n",
    "    for train_index, test_index in sss.split(X_numerical, y_encoded):\n",
    "        X_train_val, X_test = X_numerical.iloc[train_index], X_numerical.iloc[test_index]\n",
    "        y_train_val, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "    for name, model, param_grid in models:\n",
    "        print(f\"Training and evaluating {name} model...\")\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "        # Ensure string column names for features (if necessary)\n",
    "        if not all(isinstance(col, str) for col in X_train.columns):\n",
    "            X_train.columns = X_train.columns.astype(str)\n",
    "            X_val.columns = X_val.columns.astype(str)\n",
    "            X_test.columns = X_test.columns.astype(str)\n",
    "        results[f\"{name}_{split}\"] = train_and_evaluate_model(model, param_grid, X_train, y_train, X_val, y_val,\n",
    "                                                              X_test, y_test)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results).T\n",
    "\n",
    "# Display results DataFrame\n",
    "print(\"Results DataFrame:\")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33717b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2742ccf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72abfdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=results_df[['Validation Accuracy','Test Accuracy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "243cb223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.75</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.8886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.75</th>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.8198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.75</th>\n",
       "      <td>0.888533</td>\n",
       "      <td>0.8932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.8</th>\n",
       "      <td>0.8965</td>\n",
       "      <td>0.88425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.8</th>\n",
       "      <td>0.82275</td>\n",
       "      <td>0.81175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.8</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.88975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.85</th>\n",
       "      <td>0.886588</td>\n",
       "      <td>0.886667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.85</th>\n",
       "      <td>0.823294</td>\n",
       "      <td>0.814667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.85</th>\n",
       "      <td>0.897647</td>\n",
       "      <td>0.889667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Validation Accuracy Test Accuracy\n",
       "Random Forest_0.75               0.876        0.8886\n",
       "Decision Tree_0.75              0.8096        0.8198\n",
       "SVM_0.75                      0.888533        0.8932\n",
       "Random Forest_0.8               0.8965       0.88425\n",
       "Decision Tree_0.8              0.82275       0.81175\n",
       "SVM_0.8                          0.906       0.88975\n",
       "Random Forest_0.85            0.886588      0.886667\n",
       "Decision Tree_0.85            0.823294      0.814667\n",
       "SVM_0.85                      0.897647      0.889667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8cbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b2ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8de28e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Validation Report</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.75</th>\n",
       "      <td>0.876</td>\n",
       "      <td>{'0': {'precision': 0.9118303571428571, 'recal...</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>{'0': {'precision': 0.911839863713799, 'recall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.75</th>\n",
       "      <td>0.8096</td>\n",
       "      <td>{'0': {'precision': 0.854419410745234, 'recall...</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>{'0': {'precision': 0.847465034965035, 'recall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.75</th>\n",
       "      <td>0.888533</td>\n",
       "      <td>{'0': {'precision': 0.9105121293800539, 'recal...</td>\n",
       "      <td>0.8932</td>\n",
       "      <td>{'0': {'precision': 0.9038382170862567, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.8</th>\n",
       "      <td>0.8965</td>\n",
       "      <td>{'0': {'precision': 0.9170603674540683, 'recal...</td>\n",
       "      <td>0.88425</td>\n",
       "      <td>{'0': {'precision': 0.9094804499196572, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.8</th>\n",
       "      <td>0.82275</td>\n",
       "      <td>{'0': {'precision': 0.8523965141612201, 'recal...</td>\n",
       "      <td>0.81175</td>\n",
       "      <td>{'0': {'precision': 0.8478382930937676, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.8</th>\n",
       "      <td>0.906</td>\n",
       "      <td>{'0': {'precision': 0.9169656586365966, 'recal...</td>\n",
       "      <td>0.88975</td>\n",
       "      <td>{'0': {'precision': 0.9020217729393468, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest_0.85</th>\n",
       "      <td>0.886588</td>\n",
       "      <td>{'0': {'precision': 0.905337361530715, 'recall...</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>{'0': {'precision': 0.9086402266288952, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree_0.85</th>\n",
       "      <td>0.823294</td>\n",
       "      <td>{'0': {'precision': 0.8665937670858392, 'recal...</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>{'0': {'precision': 0.8710443037974683, 'recal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_0.85</th>\n",
       "      <td>0.897647</td>\n",
       "      <td>{'0': {'precision': 0.9075258239055582, 'recal...</td>\n",
       "      <td>0.889667</td>\n",
       "      <td>{'0': {'precision': 0.9013112491373361, 'recal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Validation Accuracy  \\\n",
       "Random Forest_0.75               0.876   \n",
       "Decision Tree_0.75              0.8096   \n",
       "SVM_0.75                      0.888533   \n",
       "Random Forest_0.8               0.8965   \n",
       "Decision Tree_0.8              0.82275   \n",
       "SVM_0.8                          0.906   \n",
       "Random Forest_0.85            0.886588   \n",
       "Decision Tree_0.85            0.823294   \n",
       "SVM_0.85                      0.897647   \n",
       "\n",
       "                                                    Validation Report  \\\n",
       "Random Forest_0.75  {'0': {'precision': 0.9118303571428571, 'recal...   \n",
       "Decision Tree_0.75  {'0': {'precision': 0.854419410745234, 'recall...   \n",
       "SVM_0.75            {'0': {'precision': 0.9105121293800539, 'recal...   \n",
       "Random Forest_0.8   {'0': {'precision': 0.9170603674540683, 'recal...   \n",
       "Decision Tree_0.8   {'0': {'precision': 0.8523965141612201, 'recal...   \n",
       "SVM_0.8             {'0': {'precision': 0.9169656586365966, 'recal...   \n",
       "Random Forest_0.85  {'0': {'precision': 0.905337361530715, 'recall...   \n",
       "Decision Tree_0.85  {'0': {'precision': 0.8665937670858392, 'recal...   \n",
       "SVM_0.85            {'0': {'precision': 0.9075258239055582, 'recal...   \n",
       "\n",
       "                   Test Accuracy  \\\n",
       "Random Forest_0.75        0.8886   \n",
       "Decision Tree_0.75        0.8198   \n",
       "SVM_0.75                  0.8932   \n",
       "Random Forest_0.8        0.88425   \n",
       "Decision Tree_0.8        0.81175   \n",
       "SVM_0.8                  0.88975   \n",
       "Random Forest_0.85      0.886667   \n",
       "Decision Tree_0.85      0.814667   \n",
       "SVM_0.85                0.889667   \n",
       "\n",
       "                                                          Test Report  \n",
       "Random Forest_0.75  {'0': {'precision': 0.911839863713799, 'recall...  \n",
       "Decision Tree_0.75  {'0': {'precision': 0.847465034965035, 'recall...  \n",
       "SVM_0.75            {'0': {'precision': 0.9038382170862567, 'recal...  \n",
       "Random Forest_0.8   {'0': {'precision': 0.9094804499196572, 'recal...  \n",
       "Decision Tree_0.8   {'0': {'precision': 0.8478382930937676, 'recal...  \n",
       "SVM_0.8             {'0': {'precision': 0.9020217729393468, 'recal...  \n",
       "Random Forest_0.85  {'0': {'precision': 0.9086402266288952, 'recal...  \n",
       "Decision Tree_0.85  {'0': {'precision': 0.8710443037974683, 'recal...  \n",
       "SVM_0.85            {'0': {'precision': 0.9013112491373361, 'recal...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd563c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM_0.8: 0.906"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453f20f",
   "metadata": {},
   "source": [
    "### Transformer models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9543dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishing didnt life anymore looking fellow depr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy hate live live busiest street town full ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed boyfriend want leave mum died hi ive...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said something embarrassing panic attack texti...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone please reassure im overly thinking anx...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>negative</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text_processed  topic sentiment_1  \\\n",
       "0  wishing didnt life anymore looking fellow depr...    0.0    negative   \n",
       "1  happy hate live live busiest street town full ...    2.0    negative   \n",
       "2  depressed boyfriend want leave mum died hi ive...    2.0    negative   \n",
       "3  said something embarrassing panic attack texti...    2.0    negative   \n",
       "4  someone please reassure im overly thinking anx...    1.0    negative   \n",
       "\n",
       "          tag  \n",
       "0  depression  \n",
       "1  depression  \n",
       "2  depression  \n",
       "3     anxiety  \n",
       "4     anxiety  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48539196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data[['text_processed', 'sentiment_1', 'topic']]  # Features: text and sentiment\n",
    "y = data['tag']  # Target variable: tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "128ed06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishing didnt life anymore looking fellow depr...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy hate live live busiest street town full ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed boyfriend want leave mum died hi ive...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said something embarrassing panic attack texti...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone please reassure im overly thinking anx...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>anyone anxiety give ibsgut issue dont anxiety ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>cant trust anyone sexual abuse fucked starting...</td>\n",
       "      <td>negative</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>stop freaking dying pls need serious help best...</td>\n",
       "      <td>negative</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>deal anxiety im always anxious work future met...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>one life care make want anything mostly title ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_processed sentiment_1  topic\n",
       "0      wishing didnt life anymore looking fellow depr...    negative    0.0\n",
       "1      happy hate live live busiest street town full ...    negative    2.0\n",
       "2      depressed boyfriend want leave mum died hi ive...    negative    2.0\n",
       "3      said something embarrassing panic attack texti...    negative    2.0\n",
       "4      someone please reassure im overly thinking anx...    negative    1.0\n",
       "...                                                  ...         ...    ...\n",
       "19995  anyone anxiety give ibsgut issue dont anxiety ...    negative    0.0\n",
       "19996  cant trust anyone sexual abuse fucked starting...    negative    2.0\n",
       "19997  stop freaking dying pls need serious help best...    negative    3.0\n",
       "19998  deal anxiety im always anxious work future met...    negative    0.0\n",
       "19999  one life care make want anything mostly title ...    negative    1.0\n",
       "\n",
       "[19999 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75de1cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        depression\n",
       "1        depression\n",
       "2        depression\n",
       "3           anxiety\n",
       "4           anxiety\n",
       "            ...    \n",
       "19995       anxiety\n",
       "19996       anxiety\n",
       "19997       anxiety\n",
       "19998       anxiety\n",
       "19999    depression\n",
       "Name: tag, Length: 19999, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2eda6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sssri\\AppData\\Local\\Temp\\ipykernel_3808\\2179442283.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['sentiment_1']=encoder.fit_transform(X['sentiment_1'])\n"
     ]
    }
   ],
   "source": [
    "# !pip install simpletransformers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "X['sentiment_1']=encoder.fit_transform(X['sentiment_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07647c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_processed</th>\n",
       "      <th>sentiment_1</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wishing didnt life anymore looking fellow depr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy hate live live busiest street town full ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>depressed boyfriend want leave mum died hi ive...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>said something embarrassing panic attack texti...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>someone please reassure im overly thinking anx...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>anyone anxiety give ibsgut issue dont anxiety ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>cant trust anyone sexual abuse fucked starting...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>stop freaking dying pls need serious help best...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>deal anxiety im always anxious work future met...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>one life care make want anything mostly title ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_processed  sentiment_1  topic\n",
       "0      wishing didnt life anymore looking fellow depr...            0    0.0\n",
       "1      happy hate live live busiest street town full ...            0    2.0\n",
       "2      depressed boyfriend want leave mum died hi ive...            0    2.0\n",
       "3      said something embarrassing panic attack texti...            0    2.0\n",
       "4      someone please reassure im overly thinking anx...            0    1.0\n",
       "...                                                  ...          ...    ...\n",
       "19995  anyone anxiety give ibsgut issue dont anxiety ...            0    0.0\n",
       "19996  cant trust anyone sexual abuse fucked starting...            0    2.0\n",
       "19997  stop freaking dying pls need serious help best...            0    3.0\n",
       "19998  deal anxiety im always anxious work future met...            0    0.0\n",
       "19999  one life care make want anything mostly title ...            0    1.0\n",
       "\n",
       "[19999 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "190d5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Combine text, topic, and sentiment in X\n",
    "X['combined_text'] = X['text_processed'] + \" \" + X['topic'].astype(str) + \" \" + X['sentiment_1'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6008ebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wishing didnt life anymore looking fellow depressed people gauge bad im going particularly stressful part life find often wishing didnt go motion anymore thing keeping going family pet would feel something happened werent im scared id think least every couple day anyone else feel way urgent seek help im already medicated recent stress enough seeing doctor next month 0.0 0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['combined_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1adfcb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical target variable\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb6f2ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "56934543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['combined_text'], y_encoded, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cbc916a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14999,)\n",
      "(5000,)\n",
      "(14999,)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "865451c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d9d1b72875415f978516b6f12ffd61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = ClassificationModel('bert', 'bert-base-uncased', num_labels=2,use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "40accaa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c1d5dc6c1643ab893094d72bfcd366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf53ec98d724ecb9be7d7f2288f3c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964cdc97d40e4fb693805d5253022839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 1:   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1875, 0.3217360502722363)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train_model(pd.DataFrame({'text': X_train, 'labels': y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b56c1cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea26159178f456c925d503141f20e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3864be6aa89646ca86ee23f1c9215b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(pd.DataFrame({'text': X_test, 'labels': y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c81aa77c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcc': 0.8337657845358625,\n",
       " 'accuracy': 0.9168,\n",
       " 'f1_score': 0.9164323021293692,\n",
       " 'tp': 2281,\n",
       " 'tn': 2303,\n",
       " 'fp': 232,\n",
       " 'fn': 184,\n",
       " 'auroc': 0.9705967969722065,\n",
       " 'auprc': 0.9671113810723218,\n",
       " 'eval_loss': 0.2591300995647907}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
